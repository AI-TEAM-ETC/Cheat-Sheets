{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fine-tuning\n",
    "\n",
    "Let's fine-tune both RF and XGB"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***Random Forest Classifier Fine-tuning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of trees in random forest\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 4)]\n",
    "# Number of features to consid  er at every split\n",
    "max_features = [4,6,8]\n",
    "# Maximum number of levels in tree\n",
    "max_depth = [int(x) for x in np.linspace(10, 110, num =10)]\n",
    "max_depth.append(None)\n",
    "# Minimum number of samples required to split a node\n",
    "min_samples_split = [20, 40, 60]\n",
    "# Minimum number of samples required at each leaf node\n",
    "min_samples_leaf = [2,5, 10, 20] #>1 to reduce overfitting\n",
    "# Method of selecting samples for training each tree\n",
    "bootstrap = [True] #bootstrap = [True, False]\n",
    "# Create the random grid\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "pprint(random_grid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the random grid to search for best hyperparameters\n",
    "# Fit Random Forest Classifier\n",
    "rf = RandomForestClassifier(n_jobs=-1)\n",
    "# Random search of parameters, using 3 fold cross validation, \n",
    "folds = 3 \n",
    "param_comb = 20\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 42)\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = param_comb, cv = skf.split(x_train_final,y_train), verbose=2, random_state=42, n_jobs = -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "start_time = timer() #start\n",
    "rf_random.fit(x_train_final, y_train.values.ravel())\n",
    "timer(start_time) #end\n",
    "\n",
    "# Check the best parameters\n",
    "rf_random.best_params_\n",
    "\n",
    "#30 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "RF_RS = rf_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score\n",
    "start_time = timer() #start\n",
    "RF_RS_scores= cross_validate(RF_RS, x_train_final, y_train.values.ravel(), cv=5, scoring=scoring)\n",
    "timer(start_time) #end\n",
    "\n",
    "# Store Results\n",
    "RF_RS_AUC = (RF_RS_scores['test_roc_auc']).mean().round(3)\n",
    "RF_RS_Acc = (RF_RS_scores['test_accuracy']).mean().round(3)\n",
    "RF_RS_Prec = (RF_RS_scores['test_precision']).mean().round(3)\n",
    "RF_RS_Rec = (RF_RS_scores['test_recall']).mean().round(3)\n",
    "\n",
    "# Takes 6 minutes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***XG Boost Fine-tuning***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set the parameter grid for XGBoost\n",
    "params = {\n",
    "        'min_child_weight': [1, 5, 10],\n",
    "        'gamma': [0.5, 1, 1.5, 2, 5],\n",
    "        'subsample': [0.6, 0.8, 1.0],\n",
    "        'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "        'max_depth': [3, 4, 5],\n",
    "        'n_estimators':[200,400,600]}\n",
    "\n",
    "xgb_c = xgb.XGBClassifier(learning_rate=0.02, objective='binary:logistic',\n",
    "                    silent=True, nthread=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Random search of parameters, using 5 fold cross validation, \n",
    "folds = 3\n",
    "param_comb = 20\n",
    "\n",
    "skf = StratifiedKFold(n_splits=folds, shuffle = True, random_state = 42)\n",
    "xgb_random = RandomizedSearchCV(xgb_c, param_distributions=params, n_iter=param_comb, scoring='roc_auc', n_jobs=4, cv=skf.split(x_train_final,y_train), verbose=3, random_state=42 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the random search model\n",
    "start_time = timer() #start\n",
    "xgb_random.fit(x_train_final, y_train.values.ravel())\n",
    "timer(start_time) #end\n",
    "\n",
    "# Check the best parameters\n",
    "xgb_random.best_params_\n",
    "\n",
    "#12 minutes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the model\n",
    "XGB_RS = xgb_random.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score\n",
    "start_time = timer() #start\n",
    "XGB_RS_scores= cross_validate(XGB_RS, x_train_final, y_train.values.ravel(), cv=5, scoring=scoring)\n",
    "timer(start_time) #end\n",
    "\n",
    "# Store Results\n",
    "XGB_RS_AUC = (XGB_RS_scores['test_roc_auc']).mean().round(3)\n",
    "XGB_RS_Acc = (XGB_RS_scores['test_accuracy']).mean().round(3)\n",
    "XGB_RS_Prec = (XGB_RS_scores['test_precision']).mean().round(3)\n",
    "XGB_RS_Rec = (XGB_RS_scores['test_recall']).mean().round(3)\n",
    "\n",
    "# takes 6 min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check model outputs so far\n",
    "models = [('Logistic Regression (train)', LogR_AUC, LogR_Acc, LogR_Prec, LogR_Rec),   \n",
    "          ('Random Forest Regression (train)', RF_AUC, RF_Acc, RF_Prec, RF_Rec),   \n",
    "          ('Random Forest Regression RS (train)', RF_RS_AUC, RF_RS_Acc, RF_RS_Prec, RF_RS_Rec),   \n",
    "          ('XG Boost Regressor (train)', XGB_AUC, XGB_Acc, XGB_Prec, XGB_Rec),\n",
    "          ('XG Boost Regressor RS (train)', XGB_RS_AUC, XGB_RS_Acc, XGB_RS_Prec, XGB_RS_Rec)\n",
    "        ]\n",
    "\n",
    "result = pd.DataFrame(data = models, columns=['Model', 'AUC', 'Accuracy','Precision', 'Recall'])\n",
    "result"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
